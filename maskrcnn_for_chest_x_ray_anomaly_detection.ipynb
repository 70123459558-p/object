{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "maskrcnn-for-chest-x-ray-anomaly-detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/70123459558-p/object/blob/master/maskrcnn_for_chest_x_ray_anomaly_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mask-RCNN for Chest X-ray Diagnostic - Starter"
      ],
      "metadata": {
        "id": "uabqKYaUZ9hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this notebook is to help everyone getting started with the VinBigData chest x-ray abnormalities detection competition. This is essentially an object detection problem and there is several tricky bits to it:\n",
        "* Groundtruth is provided by different experts and diagnostics can vary from one expert to another.\n",
        "* Images are massive\n",
        "* There is a significant amount of metadata\n",
        "\n",
        "To start in a simple way, I will resize all the images and only selected groundtruth from one expert and from the diseases with the largest bounding boxes. This data will then be fed to a MaskRCNN which, hopefully, will show some preliminary results."
      ],
      "metadata": {
        "id": "apxOQyNtZ9h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import pydicom\n",
        "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "uf0BZ4IfZ9iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "PuOewjKcZ9iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_folder = \"../input/vinbigdata-chest-xray-abnormalities-detection/train/\"\n",
        "df = pd.read_csv(\"../input/vinbigdata-chest-xray-abnormalities-detection/train.csv\")\n",
        "df = df.query(\"class_id<14\")\n",
        "df = df.query(\"rad_id=='R9'\")"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "q0pW8DwKZ9iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"several_issues\"] = df.duplicated(subset=['image_id'])\n",
        "df[\"box_size\"] = [(row.y_max-row.y_min)*(row.x_max-row.x_min) for idx, row in df.iterrows()]"
      ],
      "metadata": {
        "trusted": true,
        "id": "90Mwor4mZ9iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.class_name.unique()"
      ],
      "metadata": {
        "trusted": true,
        "id": "TO-FFuXgZ9ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"class_id\")[\"box_size\"].mean()"
      ],
      "metadata": {
        "trusted": true,
        "id": "VOZLti40Z9ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"class_id\")[\"box_size\"].std()"
      ],
      "metadata": {
        "trusted": true,
        "id": "pQ6gX5b1Z9il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"class_id\").image_id.count()"
      ],
      "metadata": {
        "trusted": true,
        "id": "_0QTrR7YZ9iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After checking the box sizes per abnormality, their standard deviation, and the number of examples, I decided to pick the 5 abnormalities below. I am carefully picking abnormalities with bounding boxes large enough as I will be significantly downsizing the images."
      ],
      "metadata": {
        "id": "5WmczwuDZ9iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_classes = [0,3,5,7,10]\n",
        "category_list = [\"Aortic enlargement\", \"Cardiomegaly\", \"ILD\", \"Lung Opacity\", \"Pleural effusion\"]\n",
        "filtered_df = df.query(\"class_id in @selected_classes\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "eT3rKZODZ9iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_classes_dict = {\"0\":0,\"3\":1,\"5\":2,\"7\":3,\"10\":4}\n",
        "filtered_df[\"reclass_id\"] = [selected_classes_dict[str(row.class_id)] for idx, row in filtered_df.iterrows()]"
      ],
      "metadata": {
        "trusted": true,
        "id": "Svie8PTsZ9iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "IyQWDsKtZ9i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 2 functions below allows to go from bounding boxes to the right format for a MaskRCNN."
      ],
      "metadata": {
        "id": "6F1LEdnHZ9i1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mask(img_dimensions, x_min, y_min, x_max, y_max):\n",
        "    img_height, img_width = img_dimensions\n",
        "    img_mask = np.full((img_height,img_width),0)\n",
        "    img_mask[y_min:y_max,x_min:x_max] = 255\n",
        "    \n",
        "    return img_mask.astype(np.float32)\n",
        "\n",
        "\n",
        "def rle_encoding(x):\n",
        "    dots = np.where(x.T.flatten() == 255)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    return ' '.join([str(x) for x in run_lengths])"
      ],
      "metadata": {
        "trusted": true,
        "id": "OLFaEt3GZ9i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is taken from raddar's [notebook](https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way) and helps to load the images in the cleanest way possible."
      ],
      "metadata": {
        "id": "RxT3l1RnZ9i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_xray(path, voi_lut = True, fix_monochrome = True):\n",
        "    dicom = pydicom.read_file(path)\n",
        "    \n",
        "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n",
        "    if voi_lut:\n",
        "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
        "    else:\n",
        "        data = dicom.pixel_array\n",
        "               \n",
        "    # depending on this value, X-ray may look inverted - fix that:\n",
        "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
        "        data = np.amax(data) - data\n",
        "        \n",
        "    data = data - np.min(data)\n",
        "    data = data / np.max(data)\n",
        "    data = (data * 255).astype(np.uint8)\n",
        "        \n",
        "    return data"
      ],
      "metadata": {
        "trusted": true,
        "id": "1fvCDLpWZ9i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_folder = \"../working/resized_train/\"\n",
        "os.mkdir(resized_folder)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Dp4awxuEZ9jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.groupby(\"class_id\").image_id.count()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Fq3mnrZ8Z9jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I am not going to use the full dataset in this notebook due to the processing time allowed on Kaggle Notebooks, I am sampling an even number of images per class (depending on the number of images available) to ensure I don't end up with a highly imbalanced training set."
      ],
      "metadata": {
        "id": "cBVCshvQZ9jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_filtered_df = pd.DataFrame()\n",
        "samples_per_class = 500\n",
        "for class_name in filtered_df.class_name.unique():\n",
        "    balanced_filtered_df = balanced_filtered_df.append(filtered_df.query(\"class_name==@class_name\")[:samples_per_class], \n",
        "                                                       ignore_index=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "YcZzT3HvZ9jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_filtered_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "BrSqwDfaZ9jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic_per_image = []\n",
        "\n",
        "image_size=512\n",
        "with tqdm(total=len(balanced_filtered_df)) as pbar:\n",
        "    for idx,row in balanced_filtered_df.iterrows():\n",
        "        image_id = row.image_id\n",
        "        image_df = balanced_filtered_df.query(\"image_id==@image_id\")\n",
        "        class_list = []\n",
        "        RLE_list = []\n",
        "        \n",
        "        for diagnostic_id, diagnostic in image_df.iterrows():\n",
        "            class_list.append(diagnostic.reclass_id)\n",
        "\n",
        "            dicom_image = read_xray(training_folder+image_id+\".dicom\")\n",
        "            image_dimensions = dicom_image.shape\n",
        "            \n",
        "            resized_img = cv2.resize(dicom_image, (image_size,image_size), interpolation = cv2.INTER_AREA)\n",
        "            cv2.imwrite(resized_folder+image_id+\".jpg\", resized_img) \n",
        "            \n",
        "            mask = get_mask(image_dimensions, int(diagnostic.x_min), int(diagnostic.y_min), int(diagnostic.x_max), int(diagnostic.y_max))\n",
        "            resized_mask = cv2.resize(mask, (image_size,image_size))\n",
        "            RLE_list.append(rle_encoding(resized_mask))\n",
        "        diagnostic_per_image.append({\"image_id\":image_id,\n",
        "                                     \"CategoryId\":class_list,\n",
        "                                     \"EncodedPixels\":RLE_list})\n",
        "        pbar.update(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "R_wqf61UZ9jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_df = pd.DataFrame(diagnostic_per_image)\n",
        "samples_df[\"Height\"] = image_size\n",
        "samples_df[\"Width\"] = image_size"
      ],
      "metadata": {
        "trusted": true,
        "id": "OUnkK5TuZ9jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "TO7vjmHaZ9jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a Mask-RCNN model"
      ],
      "metadata": {
        "id": "hr31hVD1Z9jV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I struggled a bit to make the Matterport MaskRCNN repo work with Tensorflow 2.3. In the end, I used a [PR created by tomgross](https://github.com/matterport/Mask_RCNN/pull/1896/commits/a3be0c2c8654628f10736c4dd88060440fab3968) as a base and only had a couple of fixes left to get everything running!"
      ],
      "metadata": {
        "id": "o_eLThrBZ9jX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ../input/maskrcnn-tf2-keras ../working/maskrcnn-tf2-keras"
      ],
      "metadata": {
        "trusted": true,
        "id": "_ny5hY21Z9jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = Path('../working/')\n",
        "ROOT_DIR = \"../../working\"\n",
        "\n",
        "NUM_CATS = len(selected_classes)\n",
        "IMAGE_SIZE = 512\n",
        "os.chdir('../working/maskrcnn-tf2-keras')\n",
        "sys.path.append(ROOT_DIR+'/maskrcnn-tf2-keras')\n",
        "from mrcnn.config import Config\n",
        "\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log"
      ],
      "metadata": {
        "trusted": true,
        "id": "YtONZJUFZ9ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COCO_WEIGHTS_PATH = '../../input/coco-weights/mask_rcnn_coco.h5'\n",
        "\n",
        "class DiagnosticConfig(Config):\n",
        "    NAME = \"Diagnostic\"\n",
        "    NUM_CLASSES = NUM_CATS + 1 # +1 for the background class\n",
        "    \n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 2 #That is the maximum with the memory available on kernels\n",
        "    \n",
        "    BACKBONE = 'resnet50'\n",
        "    \n",
        "    IMAGE_MIN_DIM = IMAGE_SIZE\n",
        "    IMAGE_MAX_DIM = IMAGE_SIZE    \n",
        "    IMAGE_RESIZE_MODE = 'none'\n",
        "\n",
        "    POST_NMS_ROIS_TRAINING = 250\n",
        "    POST_NMS_ROIS_INFERENCE = 150\n",
        "    MAX_GROUNDTRUTH_INSTANCES = 5\n",
        "    BACKBONE_STRIDES = [4, 8, 16, 32, 64]\n",
        "    BACKBONESHAPE = (8, 16, 24, 32, 48)\n",
        "    RPN_ANCHOR_SCALES = (8,16,24,32,48)\n",
        "    ROI_POSITIVE_RATIO = 0.33\n",
        "    DETECTION_MAX_INSTANCES = 300\n",
        "    DETECTION_MIN_CONFIDENCE = 0.7    \n",
        "    # STEPS_PER_EPOCH should be the number of instances \n",
        "    # divided by (GPU_COUNT*IMAGES_PER_GPU), and so should VALIDATION_STEPS;\n",
        "    # however, due to the time limit, I set them so that this kernel can be run in 9 hours\n",
        "    STEPS_PER_EPOCH = int(len(samples_df)*0.9/IMAGES_PER_GPU)\n",
        "    VALIDATION_STEPS = len(samples_df)-int(len(samples_df)*0.9/IMAGES_PER_GPU)\n",
        "    \n",
        "config = DiagnosticConfig()\n",
        "config.display()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Yu81Xe8cZ9jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiagnosticDataset(utils.Dataset):\n",
        "    def __init__(self, df):\n",
        "        super().__init__(self)\n",
        "        \n",
        "        # Add classes\n",
        "        for i, name in enumerate(category_list):\n",
        "            self.add_class(\"diagnostic\", i+1, name)\n",
        "        \n",
        "        # Add images \n",
        "        for i, row in df.iterrows():\n",
        "            self.add_image(\"diagnostic\", \n",
        "                           image_id=row.name,\n",
        "                           path=\"../\"+resized_folder+str(row.image_id)+\".jpg\", \n",
        "                           labels=row['CategoryId'],\n",
        "                           annotations=row['EncodedPixels'], \n",
        "                           height=row['Height'], width=row['Width'])\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path'], [category_list[int(x)] for x in info['labels']]\n",
        "    \n",
        "    def load_image(self, image_id):\n",
        "        return cv2.imread(self.image_info[image_id]['path'])\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "                \n",
        "        mask = np.zeros((IMAGE_SIZE, IMAGE_SIZE, len(info['annotations'])), dtype=np.uint8)\n",
        "        labels = []\n",
        "        \n",
        "        for m, (annotation, label) in enumerate(zip(info['annotations'], info['labels'])):\n",
        "            sub_mask = np.full(info['height']*info['width'], 0, dtype=np.uint8)\n",
        "            annotation = [int(x) for x in annotation.split(' ')]\n",
        "            \n",
        "            for i, start_pixel in enumerate(annotation[::2]):\n",
        "                sub_mask[start_pixel: start_pixel+annotation[2*i+1]] = 1\n",
        "\n",
        "            sub_mask = sub_mask.reshape((info['height'], info['width']), order='F')\n",
        "            sub_mask = cv2.resize(sub_mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "            \n",
        "            mask[:, :, m] = sub_mask\n",
        "            labels.append(int(label)+1)\n",
        "        return mask, np.array(labels)"
      ],
      "metadata": {
        "trusted": true,
        "id": "bIqvyHYrZ9je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_percentage = 0.9\n",
        "\n",
        "training_set_size = int(training_percentage*len(samples_df))\n",
        "validation_set_size = int((1-training_percentage)*len(samples_df))\n",
        "\n",
        "train_dataset = DiagnosticDataset(samples_df[:training_set_size])\n",
        "train_dataset.prepare()\n",
        "\n",
        "valid_dataset = DiagnosticDataset(samples_df[training_set_size:training_set_size+validation_set_size])\n",
        "valid_dataset.prepare()\n",
        "\n",
        "for i in range(10):\n",
        "    image_id = random.choice(train_dataset.image_ids)\n",
        "    image = train_dataset.load_image(image_id)\n",
        "    mask, class_ids = train_dataset.load_mask(image_id)\n",
        "    \n",
        "    visualize.display_top_masks(image, mask, class_ids, train_dataset.class_names, limit=5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "CpHJUtGkZ9jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 1e-4\n",
        "EPOCHS = [1,18]\n",
        "\n",
        "model = modellib.MaskRCNN(mode='training', config=config, model_dir=\"\")\n",
        "model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=['mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "pE_y2yNdZ9ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that there seems to be a bug which resets the loss displayed after each of the training blocks below. It did not happen in the original Matterport repo."
      ],
      "metadata": {
        "id": "DFdcuZTUZ9jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.train(train_dataset, valid_dataset,\n",
        "            learning_rate=LR,\n",
        "            epochs=EPOCHS[0],\n",
        "            layers='heads')\n",
        "\n",
        "history = model.keras_model.history.history"
      ],
      "metadata": {
        "trusted": true,
        "id": "KQ4UMOPMZ9jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.train(train_dataset, valid_dataset,\n",
        "            learning_rate=LR/10,\n",
        "            epochs=EPOCHS[1],\n",
        "            layers='all')\n",
        "\n",
        "new_history = model.keras_model.history.history\n",
        "for k in new_history: history[k] = history[k] + new_history[k]"
      ],
      "metadata": {
        "trusted": true,
        "id": "Gt1tfsEHZ9jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(EPOCHS[-1])\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.plot(epochs, history['loss'], label=\"train loss\")\n",
        "plt.plot(epochs, history['val_loss'], label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.subplot(132)\n",
        "plt.plot(epochs, history['mrcnn_class_loss'], label=\"train class loss\")\n",
        "plt.plot(epochs, history['val_mrcnn_class_loss'], label=\"valid class loss\")\n",
        "plt.legend()\n",
        "plt.subplot(133)\n",
        "plt.plot(epochs, history['mrcnn_mask_loss'], label=\"train mask loss\")\n",
        "plt.plot(epochs, history['val_mrcnn_mask_loss'], label=\"valid mask loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "tRJn9H0sZ9jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am not including the loss from the training of the heads when picking the best loss because of the bug mentioned earlier."
      ],
      "metadata": {
        "id": "wcdtBAd6Z9jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch = np.argmin(history[\"val_loss\"][1:]) + 1\n",
        "print(\"Best epoch: \", best_epoch)\n",
        "print(\"Valid loss: \", history[\"val_loss\"][1:][best_epoch-1])"
      ],
      "metadata": {
        "trusted": true,
        "id": "A92Fd1MIZ9jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict on test images"
      ],
      "metadata": {
        "id": "B1iwgouXZ9jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resized_test_folder = \"../../working/resized_test/\"\n",
        "os.mkdir(resized_test_folder)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ri3oTCvmZ9js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InferenceConfig(DiagnosticConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    IMAGE_MIN_DIM = IMAGE_SIZE\n",
        "    IMAGE_MAX_DIM = IMAGE_SIZE    \n",
        "    IMAGE_RESIZE_MODE = 'none'\n",
        "    DETECTION_MIN_CONFIDENCE = 0.8\n",
        "    DETECTION_NMS_THRESHOLD = 0.5\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "model = modellib.MaskRCNN(mode='inference', \n",
        "                          config=inference_config,\n",
        "                          model_dir=\"\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "vzYYNK3SZ9jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glob_list = glob.glob(f'diagnostic*/mask_rcnn_diagnostic_{best_epoch:04d}.h5')\n",
        "model_path = glob_list[0] if glob_list else ''\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "PXxFzJTqZ9jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.measure import find_contours\n",
        "from matplotlib.patches import Polygon\n",
        "\n",
        "\n",
        "# Fix overlapping masks\n",
        "def refine_masks(masks, rois):\n",
        "    areas = np.sum(masks.reshape(-1, masks.shape[-1]), axis=0)\n",
        "    mask_index = np.argsort(areas)\n",
        "    union_mask = np.zeros(masks.shape[:-1], dtype=bool)\n",
        "    for m in mask_index:\n",
        "        masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask))\n",
        "        union_mask = np.logical_or(masks[:, :, m], union_mask)\n",
        "    for m in range(masks.shape[-1]):\n",
        "        mask_pos = np.where(masks[:, :, m]==True)\n",
        "        if np.any(mask_pos):\n",
        "            y1, x1 = np.min(mask_pos, axis=1)\n",
        "            y2, x2 = np.max(mask_pos, axis=1)\n",
        "            rois[m, :] = [y1, x1, y2, x2]\n",
        "    return masks, rois\n",
        "\n",
        "def decode_rle(rle, height, width):\n",
        "    s = rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(height*width, dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape((height, width)).T\n",
        "\n",
        "def annotations_to_mask(annotations, height, width):\n",
        "    if isinstance(annotations, list):\n",
        "        # The annotation consists in a list of RLE codes\n",
        "        mask = np.zeros((height, width, len(annotations)))\n",
        "        for i, rle_code in enumerate(annotations):\n",
        "            mask[:, :, i] = decode_rle(rle_code, height, width)\n",
        "    else:\n",
        "        error_message = \"{} is expected to be a list or str but received {}\".format(annotation, type(annotation))\n",
        "        raise TypeError(error_message)\n",
        "    return mask\n",
        "\n",
        "def find_anomalies(dicom_image, display=False):\n",
        "\n",
        "    image_dimensions = dicom_image.shape\n",
        "\n",
        "    resized_img = cv2.resize(dicom_image, (image_size,image_size), interpolation = cv2.INTER_AREA)\n",
        "    saved_filename = resized_test_folder+\"temp_image.jpg\"\n",
        "    cv2.imwrite(saved_filename, resized_img) \n",
        "    img = cv2.imread(saved_filename)\n",
        "\n",
        "    result = model.detect([img])\n",
        "    r = result[0]\n",
        "    \n",
        "    if r['masks'].size > 0:\n",
        "        masks = np.zeros((img.shape[0], img.shape[1], r['masks'].shape[-1]), dtype=np.uint8)\n",
        "        for m in range(r['masks'].shape[-1]):\n",
        "            masks[:, :, m] = cv2.resize(r['masks'][:, :, m].astype('uint8'), \n",
        "                                        (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "        \n",
        "        y_scale = image_dimensions[0]/IMAGE_SIZE\n",
        "        x_scale = image_dimensions[1]/IMAGE_SIZE\n",
        "        rois = (r['rois'] * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n",
        "        \n",
        "        masks, rois = refine_masks(masks, rois)\n",
        "    else:\n",
        "        masks, rois = r['masks'], r['rois']\n",
        "        \n",
        "    if display:\n",
        "        visualize.display_instances(img, rois, masks, r['class_ids'], \n",
        "                                    ['bg']+category_list, r['scores'],\n",
        "                                    title=\"prediction\", figsize=(12, 12))\n",
        "    return rois, r['class_ids'], r['scores']"
      ],
      "metadata": {
        "trusted": true,
        "id": "Rz19OrY0Z9jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we run a test on several images and will display the results."
      ],
      "metadata": {
        "id": "NBeZMYm0Z9jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_folder = \"../../input/vinbigdata-chest-xray-abnormalities-detection/test/\"\n",
        "test_file_list = os.listdir(test_folder)[:5]\n",
        "\n",
        "for test_file in test_file_list:\n",
        "    dicom_image = read_xray(test_folder+test_file)\n",
        "    find_anomalies(dicom_image, display=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mevpPnisZ9j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction and generating the submission file"
      ],
      "metadata": {
        "id": "St3MBsLrZ9j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we run the prediction on the entire test set and format the results into a dataframe that will then be saved for submission. As it appeared that the model mistakenly gave several bounding boxes for Cardiomegaly, I am adding a function to keep only the best bounding box."
      ],
      "metadata": {
        "id": "6154aH_EZ9j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def keep_best_cardiomegaly_box(bbox_list, class_list, confidence_list):\n",
        "    '''\n",
        "    go through the boxes and keep only one box for \n",
        "    cardiomegaly with the highest confidence score\n",
        "    '''\n",
        "    best_cardiomegaly_score = -1\n",
        "    best_cardiomegaly_bbox = []\n",
        "    clean_bbox_list, clean_class_list, clean_confidence_list = [],[],[]\n",
        "    \n",
        "    for bbox, class_id, confidence in zip(bbox_list, class_list, confidence_list):\n",
        "        #While the class number if 3 in the dataset, it is 2 in the maskrcnn training process\n",
        "        # as I have excluded some classes\n",
        "        if class_id==2:\n",
        "            if confidence>best_cardiomegaly_score:\n",
        "                best_cardiomegaly_score = confidence\n",
        "                best_cardiomegaly_bbox = bbox\n",
        "        else:\n",
        "            clean_bbox_list.append(bbox)\n",
        "            clean_class_list.append(class_id)\n",
        "            clean_confidence_list.append(confidence)\n",
        "            \n",
        "    if best_cardiomegaly_score>0:\n",
        "        clean_bbox_list.append(best_cardiomegaly_bbox)\n",
        "        clean_class_list.append(2)\n",
        "        clean_confidence_list.append(best_cardiomegaly_score)\n",
        "        \n",
        "    return clean_bbox_list, clean_class_list, clean_confidence_list"
      ],
      "metadata": {
        "trusted": true,
        "id": "jiu6GuhIZ9j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "test_file_list = os.listdir(test_folder)\n",
        "with tqdm(total=len(test_file_list)) as pbar:\n",
        "    for image_filename in test_file_list:\n",
        "        dicom_image = read_xray(test_folder+image_filename)\n",
        "        image_dimensions = dicom_image.shape\n",
        "        bbox_list, class_list, confidence_list = find_anomalies(dicom_image, display=False)\n",
        "        prediction_string = \"\"\n",
        "        \n",
        "        if len(bbox_list)>0:\n",
        "                    \n",
        "            bbox_list, class_list, confidence_list = keep_best_cardiomegaly_box(bbox_list, class_list, confidence_list)\n",
        "            \n",
        "            for bbox, class_id, confidence in zip(bbox_list, class_list, confidence_list):\n",
        "                class_id = next(key for key, value in selected_classes_dict.items() if value == int(class_id)-1)\n",
        "                confidence_score = str(round(confidence,3))\n",
        "\n",
        "                #HACK: I had to rescale the bounding box here. For some reason,\n",
        "                #It did not do it in the prediction function.\n",
        "                y_scale = image_dimensions[0]/image_size\n",
        "                x_scale = image_dimensions[1]/image_size\n",
        "                rescaled_bbox = (bbox * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n",
        "\n",
        "                #organise the bbox into xmin, ymin, xmax, ymax\n",
        "                ymin = image_dimensions[0]-rescaled_bbox[2]\n",
        "                ymax = image_dimensions[0]-rescaled_bbox[0]\n",
        "                xmin = rescaled_bbox[1]\n",
        "                xmax = rescaled_bbox[3]\n",
        "\n",
        "                prediction_string += \"{} {} {} {} {} {} \".format(class_id, confidence_score, xmin, ymin, xmax, ymax)\n",
        "            results.append({\"image_id\":image_filename.replace(\".dicom\",\"\"), \"PredictionString\":prediction_string.strip()})\n",
        "        else:\n",
        "            results.append({\"image_id\":image_filename.replace(\".dicom\",\"\"), \"PredictionString\":\"14 1.0 0 0 1 1\"})\n",
        "        pbar.update(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "EGDebO3DZ9j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "trusted": true,
        "id": "qQheLT0lZ9j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "zNChY4PeZ9j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.to_csv('../submission.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Z0vpyr_rZ9j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Thanks for reading this notebook! If you found this notebook helpful, please give it an upvote. It is always greatly appreciated"
      ],
      "metadata": {
        "id": "tzFnA3FsZ9j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#clear all the images from the working directory\n",
        "!rm -rf ../../working/resized_train/\n",
        "!rm -rf ../../working/resized_test/"
      ],
      "metadata": {
        "trusted": true,
        "id": "cTUA6Nb9Z9kB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}